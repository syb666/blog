## 中国天气网爬取之华北城市数据爬取
```
import requests
from bs4 import BeautifulSoup

def parser_page(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.75 Safari/537.36'
    }
    response = requests.get(url,headers=headers)
    text = response.content.decode('utf-8')
    # return text
    soup = BeautifulSoup(text,'lxml')
    conMidtab = soup.find('div',attrs={"class":"conMidtab"})#获取某个标签下的某个属性
    tables = conMidtab.find_all('table')
    for table in tables:
        trs = table.find_all('tr')[2:]
        for tr in trs:
            tds = tr.find_all('td')
            city_td = tds[0]
            city = list(city_td.stripped_strings)[0]#获取值所有子孙节点文本的第一个
            temp_td = tds[-2]
            min_temp = list(temp_td.stripped_strings)[0]
            print(city,min_temp)

def main():
    url = 'http://www.weather.com.cn/textFC/hb.shtml'
    parser_page(url)

if __name__ == '__main__':
    main()
```

## 中国天气网爬虫之所有城市数据爬取

```
# -*- coding: utf-8 -*-
import requests
from bs4 import BeautifulSoup

def parser_page(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.75 Safari/537.36'
    }
    response = requests.get(url,headers=headers)
    text = response.content.decode('utf-8')
    # return text
    soup = BeautifulSoup(text,'html5lib')#解析速度慢
    conMidtab = soup.find('div',attrs={"class":"conMidtab"})#获取某个标签下的某个属性
    tables = conMidtab.find_all('table')
    for table in tables:
        trs = table.find_all('tr')[2:]
        for index,tr in enumerate(trs):
            tds = tr.find_all('td')
            city_td = tds[0]
            if index==0:
                city_td = tds[1]
            city = list(city_td.stripped_strings)[0]#获取值所有子孙节点文本的第一个
            temp_td = tds[-2]
            min_temp = list(temp_td.stripped_strings)[0]
            print(city,min_temp)

def main():
    urls = [
        'http://www.weather.com.cn/textFC/hb.shtml',
        'http://www.weather.com.cn/textFC/db.shtml',
        'http://www.weather.com.cn/textFC/hd.shtml',
        'http://www.weather.com.cn/textFC/hz.shtml',
        'http://www.weather.com.cn/textFC/hn.shtml',
        'http://www.weather.com.cn/textFC/xb.shtml',
        'http://www.weather.com.cn/textFC/xn.shtml',
        'http://www.weather.com.cn/textFC/gat.shtml',
    ]
    # url = 'http://www.weather.com.cn/textFC/gat.shtml'
    for url in urls:
        parser_page(url)

if __name__ == '__main__':
    main()
```
## 中国天气网爬虫之数据可视化
```
# -*- coding: utf-8 -*-
import requests
from bs4 import BeautifulSoup
from pyecharts import Bar

ALL_DATE = []
def parser_page(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.75 Safari/537.36'
    }
    response = requests.get(url,headers=headers)
    text = response.content.decode('utf-8')
    # return text
    soup = BeautifulSoup(text,'html5lib')#解析速度慢
    conMidtab = soup.find('div',attrs={"class":"conMidtab"})#获取某个标签下的某个属性
    tables = conMidtab.find_all('table')
    for table in tables:
        trs = table.find_all('tr')[2:]
        for index,tr in enumerate(trs):
            tds = tr.find_all('td')
            city_td = tds[0]
            if index==0:
                city_td = tds[1]
            city = list(city_td.stripped_strings)[0]#获取值所有子孙节点文本的第一个
            temp_td = tds[-2]
            min_temp = list(temp_td.stripped_strings)[0]
            ALL_DATE.append({"city":city,"min_temp":int(min_temp)})
            # print({"city":city,"min_temp":min_temp})

def main():
    urls = [
        'http://www.weather.com.cn/textFC/hb.shtml',
        'http://www.weather.com.cn/textFC/db.shtml',
        'http://www.weather.com.cn/textFC/hd.shtml',
        'http://www.weather.com.cn/textFC/hz.shtml',
        'http://www.weather.com.cn/textFC/hn.shtml',
        'http://www.weather.com.cn/textFC/xb.shtml',
        'http://www.weather.com.cn/textFC/xn.shtml',
        'http://www.weather.com.cn/textFC/gat.shtml',
    ]
    # url = 'http://www.weather.com.cn/textFC/gat.shtml'
    for url in urls:
        parser_page(url)
    # 分析数据
    # 根据最低气温排序
    ALL_DATE.sort(key=lambda data: data['min_temp'])  # date是传递的参数
    data = ALL_DATE[:10]
    # print(ALL_DATE[:10])
    cities = []
    cities = list(map(lambda x:x['city'],data))
    temps = list(map(lambda x:x['min_temp'],data))
    chart = Bar("中国天气最低气温排行榜")
    chart.add('',cities,temps)
    chart.render('temperature.html')

if __name__ == '__main__':
    main()
```

